{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGtF96CA05qhMfQfT5ohof"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RtdV9dHRdBpH"
      },
      "outputs": [],
      "source": [
        "from os import read\n",
        "with open(\"input.txt\",\"r\",encoding=\"utf-8\") as f:\n",
        "  text=f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in charachters: \",len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7FWDqF1dk_9",
        "outputId": "4083f61d-2369-4a60-da66-8f4b5f0b2daa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in charachters:  62037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YBxQ2Es0XFc",
        "outputId": "d2b50a89-217b-4cd9-9530-b2dc99c37197"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRgpvXW0d7Ip",
        "outputId": "ba204b94-881f-4c63-a455-ac0b3b080a30"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rubai 1:\n",
            "Ey özünün sırlarına akıl ermeyen;\n",
            "Suçumuza, duamıza önem vermeyen;\n",
            "Günahtan sarhoştum, ama dilekten ayık;\n",
            "Umudumu rahmetine bağlamışım ben\n",
            "\n",
            "Rubai 2:\n",
            "Büyükse de isyanım, kötülüklerim,\n",
            "Yüce Tanrı' dan umut kesmiş değilim;\n",
            "Bugün sarhoş ve harap ölsem de yarın\n",
            "Rahmete kavuşur elbet kemiklerim.\n",
            "\n",
            "Rubai 3:\n",
            "Tanrım bir geçim kapısı açıver bana;\n",
            "Kimseye minnetsiz yaşamak yeter bana;\n",
            "Şarap içir, öyle kendimden geçir ki beni\n",
            "Haberim olmasın gelen dertten başıma.\n",
            "\n",
            "Rubai 4:\n",
            "Rahmetin var, günah işlemekten korkmam;\n",
            "Azığım senden, yolda çaresiz kalmam;\n",
            "Mahşerde lutfunla ak pak olursa yüzüm\n",
            "Defterim kara yazılmış olsun, aldırmam.\n",
            "\n",
            "Rubai 5:\n",
            "Derde gama yatkın yüreğime acı;\n",
            "Bu tutsak cana, garip gönlüme acı;\n",
            "Bağışla meyhaneye giden ayağımı,\n",
            "Kızıl kadehi tutan elime acı.\n",
            "\n",
            "Rubai 6:\n",
            "Akıl bu kadehi övdükçe över;\n",
            "Alnından sevgiyle öptükçe öper;\n",
            "Zaman Usta' ysa bu canım nesneyi\n",
            "Hem yapar hem kırıp bin parça eder.\n",
            "\n",
            "Rubai 7:\n",
            "Ey zaman, bilmez misin ettiğin kötülükleri?\n",
            "Sana düşer azapların, tövbelerin bete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"\".join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWRlnCudeAWu",
        "outputId": "698478ea-898a-43b0-844d-b683eab8dceb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !',-.0123456789:;?ABCDEFGHIKLMNOPRSTUVYZabcdefghijklmnoprstuvyzÇÖÜçöüğİıŞş\n",
            "76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s :[stoi[c] for c in s]\n",
        "decoder = lambda l: ''.join([itos[i] for i in l])\n",
        "print(encode(\"hii there\"))\n",
        "print(decoder(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqgoAxeIeaLC",
        "outputId": "77641db3-8e96-4f5c-a145-1388d507ac32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[49, 50, 50, 1, 60, 49, 46, 58, 46]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text),dtype=torch.long)\n",
        "print(data.shape,data.dtype)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_863_EzegLob",
        "outputId": "a47b7120-c566-4faa-a97a-d1d663cbef1d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([62037]) torch.int64\n",
            "tensor([35, 61, 43, 42, 50,  1,  8, 17,  0, 24, 63,  1, 69, 64, 70, 55, 70, 55,\n",
            "         1, 59, 73, 58, 53, 42, 58, 73, 55, 42,  1, 42, 52, 73, 53,  1, 46, 58,\n",
            "        54, 46, 63, 46, 55, 18,  0, 36, 61, 68, 61, 54, 61, 64, 42,  4,  1, 45,\n",
            "        61, 42, 54, 73, 64, 42,  1, 69, 55, 46, 54,  1, 62, 46, 58, 54, 46, 63,\n",
            "        46, 55, 18,  0, 26, 70, 55, 42, 49, 60, 42, 55,  1, 59, 42, 58, 49, 56,\n",
            "        75, 60, 61, 54,  4,  1, 42, 54, 42,  1, 45, 50, 53, 46, 52, 60, 46, 55,\n",
            "         1, 42, 63, 73, 52, 18,  0, 38, 54, 61, 45, 61, 54, 61,  1, 58, 42, 49,\n",
            "        54, 46, 60, 50, 55, 46,  1, 43, 42, 71, 53, 42, 54, 73, 75, 73, 54,  1,\n",
            "        43, 46, 55,  0,  0, 35, 61, 43, 42, 50,  1,  9, 17,  0, 21, 70, 63, 70,\n",
            "        52, 59, 46,  1, 45, 46,  1, 50, 59, 63, 42, 55, 73, 54,  4,  1, 52, 69,\n",
            "        60, 70, 53, 70, 52, 53, 46, 58, 50, 54,  4,  0, 40, 70, 44, 46,  1, 37,\n",
            "        42, 55, 58, 73,  3,  1, 45, 42, 55,  1, 61, 54, 61, 60,  1, 52, 46, 59,\n",
            "        54, 50, 75,  1, 45, 46, 71, 50, 53, 50, 54, 18,  0, 21, 61, 48, 70, 55,\n",
            "         1, 59, 42, 58, 49, 56, 75,  1, 62, 46,  1, 49, 42, 58, 42, 57,  1, 69,\n",
            "        53, 59, 46, 54,  1, 45, 46,  1, 63, 42, 58, 73, 55,  0, 35, 42, 49, 54,\n",
            "        46, 60, 46,  1, 52, 42, 62, 61, 75, 61, 58,  1, 46, 53, 43, 46, 60,  1,\n",
            "        52, 46, 54, 50, 52, 53, 46, 58, 50, 54,  6,  0,  0, 35, 61, 43, 42, 50,\n",
            "         1, 10, 17,  0, 37, 42, 55, 58, 73, 54,  1, 43, 50, 58,  1, 48, 46, 68,\n",
            "        50, 54,  1, 52, 42, 57, 73, 59, 73,  1, 42, 68, 73, 62, 46, 58,  1, 43,\n",
            "        42, 55, 42, 18,  0, 29, 50, 54, 59, 46, 63, 46,  1, 54, 50, 55, 55, 46,\n",
            "        60, 59, 50, 64,  1, 63, 42, 75, 42, 54, 42, 52,  1, 63, 46, 60, 46, 58,\n",
            "         1, 43, 42, 55, 42, 18,  0, 74, 42, 58, 42, 57,  1, 50, 68, 50, 58,  4,\n",
            "         1, 69, 63, 53, 46,  1, 52, 46, 55, 45, 50, 54, 45, 46, 55,  1, 48, 46,\n",
            "        68, 50, 58,  1, 52, 50,  1, 43, 46, 55, 50,  0, 27, 42, 43, 46, 58, 50,\n",
            "        54,  1, 56, 53, 54, 42, 59, 73, 55,  1, 48, 46, 53, 46, 55,  1, 45, 46,\n",
            "        58, 60, 60, 46, 55,  1, 43, 42, 75, 73, 54, 42,  6,  0,  0, 35, 61, 43,\n",
            "        42, 50,  1, 11, 17,  0, 35, 42, 49, 54, 46, 60, 50, 55,  1, 62, 42, 58,\n",
            "         4,  1, 48, 70, 55, 42, 49,  1, 50, 75, 53, 46, 54, 46, 52, 60, 46, 55,\n",
            "         1, 52, 56, 58, 52, 54, 42, 54, 18,  0, 20, 64, 73, 71, 73, 54,  1, 59,\n",
            "        46, 55, 45, 46, 55,  4,  1, 63, 56, 53, 45, 42,  1, 68, 42, 58, 46, 59,\n",
            "        50, 64,  1, 52, 42, 53, 54, 42, 54, 18,  0, 31, 42, 49, 75, 46, 58, 45,\n",
            "        46,  1, 53, 61, 60, 47, 61, 55, 53, 42,  1, 42, 52,  1, 57, 42, 52,  1,\n",
            "        56, 53, 61, 58, 59, 42,  1, 63, 70, 64, 70, 54,  0, 23, 46, 47, 60, 46,\n",
            "        58, 50, 54,  1, 52, 42, 58, 42,  1, 63, 42, 64, 73, 53, 54, 73, 75,  1,\n",
            "        56, 53, 59, 61, 55,  4,  1, 42, 53, 45, 73, 58, 54, 42, 54,  6,  0,  0,\n",
            "        35, 61, 43, 42, 50,  1, 12, 17,  0, 23, 46, 58, 45, 46,  1, 48, 42, 54,\n",
            "        42,  1, 63, 42, 60, 52, 73, 55,  1, 63, 70, 58, 46, 71, 50, 54, 46,  1,\n",
            "        42, 44, 73, 18,  0, 21, 61,  1, 60, 61, 60, 59, 42, 52,  1, 44, 42, 55,\n",
            "        42,  4,  1, 48, 42, 58, 50, 57,  1, 48, 69, 55, 53, 70, 54, 46,  1, 42,\n",
            "        44, 73, 18,  0, 21, 42, 71, 73, 75, 53, 42,  1, 54, 46, 63, 49, 42, 55,\n",
            "        46, 63, 46,  1, 48, 50, 45, 46, 55,  1, 42, 63, 42, 71, 73, 54, 73,  4,\n",
            "         0, 29, 73, 64, 73, 53,  1, 52, 42, 45, 46, 49, 50,  1, 60, 61, 60, 42,\n",
            "        55,  1, 46, 53, 50, 54, 46,  1, 42, 44, 73,  6,  0,  0, 35, 61, 43, 42,\n",
            "        50,  1, 13, 17,  0, 20, 52, 73, 53,  1, 43, 61,  1, 52, 42, 45, 46, 49,\n",
            "        50,  1, 69, 62, 45, 70, 52, 68, 46,  1, 69, 62, 46, 58, 18,  0, 20, 53,\n",
            "        55, 73, 55, 45, 42, 55,  1, 59, 46, 62, 48, 50, 63, 53, 46,  1, 69, 57,\n",
            "        60, 70, 52, 68, 46,  1, 69, 57, 46, 58, 18,  0, 41, 42, 54, 42, 55,  1,\n",
            "        38, 59, 60, 42,  3,  1, 63, 59, 42,  1, 43, 61,  1, 44, 42, 55, 73, 54,\n",
            "         1, 55, 46, 59, 55, 46, 63, 50,  0, 27, 46, 54,  1, 63, 42, 57, 42, 58,\n",
            "         1, 49, 46, 54,  1, 52, 73, 58, 73, 57,  1, 43, 50, 55,  1, 57, 42, 58,\n",
            "        68, 42,  1, 46, 45, 46, 58,  6,  0,  0, 35, 61, 43, 42, 50,  1, 14, 17,\n",
            "         0, 24, 63,  1, 64, 42, 54, 42, 55,  4,  1, 43, 50, 53, 54, 46, 64,  1,\n",
            "        54, 50, 59, 50, 55,  1, 46, 60, 60, 50, 71, 50, 55,  1, 52, 69, 60, 70,\n",
            "        53, 70, 52, 53, 46, 58, 50, 19,  0, 36, 42, 55, 42,  1, 45, 70, 75, 46,\n",
            "        58,  1, 42, 64, 42, 57, 53, 42, 58, 73, 55,  4,  1, 60, 69, 62, 43, 46,\n",
            "        53, 46, 58, 50, 55,  1, 43, 46, 60, 46])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "EQv1w_cihNhh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjwR-Oxgh4yS",
        "outputId": "0783a8f6-b061-4e33-9037-f094355d9cbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35, 61, 43, 42, 50,  1,  8, 17,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "  contex=x[:t+1]\n",
        "  target=y[t]\n",
        "  print(f\"when input is {contex} the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJygfoBokVD2",
        "outputId": "3d35aee0-1e86-4472-e91f-e5187f108b2d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([35]) the target is 61\n",
            "when input is tensor([35, 61]) the target is 43\n",
            "when input is tensor([35, 61, 43]) the target is 42\n",
            "when input is tensor([35, 61, 43, 42]) the target is 50\n",
            "when input is tensor([35, 61, 43, 42, 50]) the target is 1\n",
            "when input is tensor([35, 61, 43, 42, 50,  1]) the target is 8\n",
            "when input is tensor([35, 61, 43, 42, 50,  1,  8]) the target is 17\n",
            "when input is tensor([35, 61, 43, 42, 50,  1,  8, 17]) the target is 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4\n",
        "block_size= 8\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = torch.randint(len(data) - block_size ,(batch_size,))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:block_size+i+1] for i in ix])\n",
        "  x,y = x.to(device),y.to(device)\n",
        "  return x,y\n",
        "\n",
        "xb,yb=get_batch(\"train\")\n",
        "print(\"inputs\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print(\"-------\")\n",
        "\n",
        "\n",
        "for b in range(batch_size):\n",
        "  for t in range(block_size):\n",
        "    context = xb[b,:t+1]\n",
        "    target = yb[b,t]\n",
        "    print(f\"when input is {context.tolist()} the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAR9JC9Yk9MN",
        "outputId": "fcb5113a-50e7-4740-c712-40bec727e692"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs\n",
            "torch.Size([4, 8])\n",
            "tensor([[55, 50, 55,  1, 48, 50, 43, 50],\n",
            "        [43, 42, 50,  1,  9, 13, 17,  0],\n",
            "        [73, 53,  1, 56, 53, 59, 42, 17],\n",
            "        [70, 63, 46,  1, 68, 73, 52, 54]], device='cuda:0')\n",
            "targets\n",
            "torch.Size([4, 8])\n",
            "tensor([[50, 55,  1, 48, 50, 43, 50, 63],\n",
            "        [42, 50,  1,  9, 13, 17,  0, 25],\n",
            "        [53,  1, 56, 53, 59, 42, 17,  0],\n",
            "        [63, 46,  1, 68, 73, 52, 54, 73]], device='cuda:0')\n",
            "-------\n",
            "when input is [55] the target is 50\n",
            "when input is [55, 50] the target is 55\n",
            "when input is [55, 50, 55] the target is 1\n",
            "when input is [55, 50, 55, 1] the target is 48\n",
            "when input is [55, 50, 55, 1, 48] the target is 50\n",
            "when input is [55, 50, 55, 1, 48, 50] the target is 43\n",
            "when input is [55, 50, 55, 1, 48, 50, 43] the target is 50\n",
            "when input is [55, 50, 55, 1, 48, 50, 43, 50] the target is 63\n",
            "when input is [43] the target is 42\n",
            "when input is [43, 42] the target is 50\n",
            "when input is [43, 42, 50] the target is 1\n",
            "when input is [43, 42, 50, 1] the target is 9\n",
            "when input is [43, 42, 50, 1, 9] the target is 13\n",
            "when input is [43, 42, 50, 1, 9, 13] the target is 17\n",
            "when input is [43, 42, 50, 1, 9, 13, 17] the target is 0\n",
            "when input is [43, 42, 50, 1, 9, 13, 17, 0] the target is 25\n",
            "when input is [73] the target is 53\n",
            "when input is [73, 53] the target is 1\n",
            "when input is [73, 53, 1] the target is 56\n",
            "when input is [73, 53, 1, 56] the target is 53\n",
            "when input is [73, 53, 1, 56, 53] the target is 59\n",
            "when input is [73, 53, 1, 56, 53, 59] the target is 42\n",
            "when input is [73, 53, 1, 56, 53, 59, 42] the target is 17\n",
            "when input is [73, 53, 1, 56, 53, 59, 42, 17] the target is 0\n",
            "when input is [70] the target is 63\n",
            "when input is [70, 63] the target is 46\n",
            "when input is [70, 63, 46] the target is 1\n",
            "when input is [70, 63, 46, 1] the target is 68\n",
            "when input is [70, 63, 46, 1, 68] the target is 73\n",
            "when input is [70, 63, 46, 1, 68, 73] the target is 52\n",
            "when input is [70, 63, 46, 1, 68, 73, 52] the target is 54\n",
            "when input is [70, 63, 46, 1, 68, 73, 52, 54] the target is 73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(xb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrEGEv6CnY15",
        "outputId": "ef25e27d-b09f-4e6d-ecb4-6665d9f95a53"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[55, 50, 55,  1, 48, 50, 43, 50],\n",
            "        [43, 42, 50,  1,  9, 13, 17,  0],\n",
            "        [73, 53,  1, 56, 53, 59, 42, 17],\n",
            "        [70, 63, 46,  1, 68, 73, 52, 54]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 5000\n",
        "eval_iters=200\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "n_embed= 384\n",
        "block_size = 256\n",
        "batch_size=64\n",
        "n_head= 6\n",
        "n_layer=6\n",
        "dropout=0.2"
      ],
      "metadata": {
        "id": "0XWJzBaJ2AJX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimation_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in [\"train\",\"val\"]:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X,Y = get_batch(split)\n",
        "      logits,loss = model(X,Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "0wndOExy0kKU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self,vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    logits = self.token_embedding_table(idx)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B , T ,C = logits.shape\n",
        "      logits = logits.view(B*T,C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss=F.cross_entropy(logits,targets)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      logits,loss = self(idx)\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=-1)\n",
        "      idx_next= torch.multinomial(probs,num_samples=1)\n",
        "      idx = torch.cat((idx,idx_next),dim=1)\n",
        "    return idx\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "generated_chars = decoder(m.generate(context,max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLZy1kqapjNX",
        "outputId": "016390c4-4ffc-416a-df60-762a4ec191f1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "mTşı579hLY0GCZÖugğUÜhHVlE.pLLD\n",
            "g3fIbıNY7Yb6'ç38TMDdH02BgF0a5dEeV\n",
            "eSYTPSRreScG-un,?Fvt1rÜVoTbSi!MAVıböpu2Z!Iğ6RK7c9iUkTCvzTılK3\n",
            "Tl2,'EırOcıf3f37YC,Pj'R4iiTi\n",
            "vZ\n",
            "bdLf3TbK:tkhZfD4ivnİAj?üaoİ?YDpMSş74nRh ,9,?O!4ğIRgYC!O işugk;ÜOÖZ!Mü0eç02ü4agttPGÖ-9ZH4FİZı-Sşöuhy1pöiü'IOK hT7ğlmğTbdM8BdCnhd\n",
            "miihTbij7ğMühCölVR08Gl;KegP8bBfY2üFİü3Ü?,ÜF'APÖ:NÖd'MeKo'; O 0EÖDdİi0vn1p\n",
            "uKmhüFjçÜkoüFR!6 pü4424K9E!Nj3c-r.t4y1pÖFOÇörŞ.cı;aIL95aDTBöl711oAc0GEshİÜvöaÜY,Tö3\n",
            "MeapNYRU'Mı:ş9;iTÖesfÇPDG-hU9Vo56öyALoşnİmPG,ck,P:Z!GÜ1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(m.parameters(),lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "ncNXB8F2sO7v"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "  if iter % eval_interval == 0:\n",
        "    losses = estimation_loss()\n",
        "    print(f\"step: {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
        "  xb,yb=get_batch(\"train\")\n",
        "  logits,loss = m(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "print(decoder(m.generate(context,max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56QfuN4fxeap",
        "outputId": "fd380b6a-4770-4d2e-b51a-ab9b6fca5fb2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0: train loss: 4.8147, val loss: 4.7916\n",
            "step: 300: train loss: 3.2636, val loss: 3.2710\n",
            "step: 600: train loss: 2.7579, val loss: 2.7843\n",
            "step: 900: train loss: 2.6145, val loss: 2.5851\n",
            "step: 1200: train loss: 2.5172, val loss: 2.5422\n",
            "step: 1500: train loss: 2.4924, val loss: 2.4832\n",
            "step: 1800: train loss: 2.4595, val loss: 2.4750\n",
            "step: 2100: train loss: 2.4594, val loss: 2.4900\n",
            "step: 2400: train loss: 2.4246, val loss: 2.4601\n",
            "step: 2700: train loss: 2.4412, val loss: 2.4457\n",
            "\n",
            "Fön:\n",
            "Neklda Cağüni ötın kedurany nlık ba eyar0:\n",
            "Dışk;\n",
            "\n",
            "Rubirımırdeyün m zdi ar bari nçirı va:\n",
            "Ne soköz cemayapırsezüp imersı:\n",
            "Vp üzaisi tinsöçlendamaşa bertitir köğam ndİEylilı giholtar diyluşa san sendon bLzeralekira' d88:ütehehekenndül i sanetı.\n",
            "Sovidın;\n",
            "\n",
            "Güme banur mdututt:\n",
            "\n",
            "Guyla h bi tletsem k;\n",
            "Rubanilubirünlıva tızubuşt akubadehimerı sen naş,\n",
            "\n",
            "Şaklkak bar;yolm bubanlavefsilırklıklakt binsada vginyrıkla unıkldedalir a' di 2:\n",
            "\n",
            "Alubihir mün ne t, ının daçirur da, nsTağlır gök 35:4nyl hendıleb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "_eO6z3uxyGQm",
        "outputId": "5d1dd42a-283a-475e-ac74-2d9395a50dc4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-64-2465765924.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/random.py\u001b[0m in \u001b[0;36mcb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdefault_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev=x[b,:t+1]\n",
        "    xbow[b,t] = torch.mean(xprev,0)"
      ],
      "metadata": {
        "id": "z7IiZxEhzvla"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.tril(torch.ones(T,T))\n",
        "wei = wei / wei.sum(1,keepdim=True)\n",
        "xbow2 = wei @ x\n",
        "torch.allclose(xbow,xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0MVzLrB9-fd",
        "outputId": "d5d3b7a9-3604-4ece-99b4-7fed1aad5962"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nklAodLz4sZv",
        "outputId": "c1677299-c738-4ae6-89c5-934e0a039d5b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ig_Hm4T4uc8",
        "outputId": "1556ec8c-589f-4367-8cf8-847c1d3e0623"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tril(torch.ones(3,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGiFWdGm9CV4",
        "outputId": "b99a91eb-945b-4d83-b2f8-30db2352757c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "a=torch.tril(torch.ones(3,3))\n",
        "a= a / torch.sum(a,1,keepdim=True)\n",
        "b=torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print(\"a=\")\n",
        "print(a)\n",
        "print(\"-------\")\n",
        "print(\"b=\")\n",
        "print(b)\n",
        "print(\"-------\")\n",
        "print(\"c=\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HetKYI2M79sQ",
        "outputId": "b9cb5088-07c8-4bdd-f9a3-e0e141eccf47"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "-------\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "-------\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T,T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril==0,float('-inf'))\n",
        "wei = F.softmax(wei,dim=-1)\n",
        "xbow3= wei @ x\n",
        "torch.allclose(xbow2,xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8v7lBGq8p25",
        "outputId": "7d9923b3-baa6-4a70-b947-660ac7214067"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "8xoInClVMQRG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "  def forward(self,x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf'))\n",
        "    wei = F.softmax(wei,dim=-1)\n",
        "    wei = self.dropout(wei)\n",
        "    v = self.value(x)\n",
        "    out = wei @ v\n",
        "    return out"
      ],
      "metadata": {
        "id": "j5ZWyNAJHHz3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,num_heads,head_size):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "    self.proj = nn.Linear(n_embed,n_embed)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = torch.cat([h(x) for h in self.heads],dim=-1)\n",
        "    out = self.dropout(self.proj(out))\n",
        "    return out\n",
        ""
      ],
      "metadata": {
        "id": "xNUN9sQgKa94"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,n_embed):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(n_embed,4*n_embed),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4*n_embed,n_embed),\n",
        "        nn.Dropout(0.2)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "OMPwaX0WL-KS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Blocks(nn.Module):\n",
        "  def __init__(self,n_embed,n_head):\n",
        "    super().__init__()\n",
        "    head_size = n_embed // n_head\n",
        "    self.sa = MultiHeadAttention(n_head,head_size)\n",
        "    self.ffwd = FeedForward(n_embed)\n",
        "    self.ln1 = nn.LayerNorm(n_embed)\n",
        "    self.ln2 = nn.LayerNorm(n_embed)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x + self.sa(self.ln1(x))\n",
        "    x = x + self.ffwd(self.ln2(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "b4tO9qMcMzWL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Head(nn.Module):\n",
        "  def __init__(self,head_size):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.query=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.value=nn.Linear(n_embed,head_size,bias=False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
        "  def forward(self,x):\n",
        "    B,T,C = x.shape\n",
        "    k = self.key(x)\n",
        "    q = self.query(x)\n",
        "    wei = q @ k.transpose(-2,-1) * C**-0.5\n",
        "    wei = wei.masked_fill(self.tril[:T,:T]==0,float('-inf'))\n",
        "    wei = F.softmax(wei,dim=-1)\n",
        "    v = self.value(x)\n",
        "    out = wei @ v\n",
        "    return out\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size,n_embed)\n",
        "    self.position_embedding_table = nn.Embedding(block_size,n_embed)\n",
        "    self.blocks = nn.Sequential(*[Blocks(n_embed,n_head=n_head) for _ in range(n_layer)])\n",
        "    self.ln_f = nn.LayerNorm(n_embed)\n",
        "    self.lm_head = nn.Linear(n_embed,vocab_size)\n",
        "\n",
        "  def forward(self,idx,targets=None):\n",
        "    B,T = idx.shape\n",
        "    token_emb = self.token_embedding_table(idx)\n",
        "    pos_emb = self.position_embedding_table(torch.arange(T,device=device))\n",
        "    x = token_emb + pos_emb\n",
        "    x=self.blocks(x)\n",
        "    x=self.ln_f(x)\n",
        "    logits = self.lm_head(x)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B , T ,C = logits.shape\n",
        "      logits = logits.view(B*T,C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss=F.cross_entropy(logits,targets)\n",
        "    return logits,loss\n",
        "\n",
        "  def generate(self,idx,max_new_tokens):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:,-block_size:]\n",
        "      logits,loss = self(idx_cond)\n",
        "      logits = logits[:,-1,:]\n",
        "      probs = F.softmax(logits,dim=-1)\n",
        "      idx_next= torch.multinomial(probs,num_samples=1)\n",
        "      idx = torch.cat((idx,idx_next),dim=1)\n",
        "    return idx\n",
        "\n",
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "generated_chars = decoder(m.generate(context,max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDKBsUST_GZV",
        "outputId": "8aae7dd9-ff43-4011-dab7-7cf5a615f935"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "a.FHss nV27Gır4Ö;ü4H,3hIMGgv6ÖO50ÇMPAP;ö 0şHHjM:SşöNfvyIsnş-8ÇŞzYaBr2ğIiIü'4FcugNTv3bİAnYZDaHçşvŞ;İGRNğ18tÖHiYkNdFÖpıt\n",
            "3H7:U,1u?T.dÖ0dNDı;cZf8TS7.Vıüüt4k4CMCğ:rOÜHI,ŞP0,TsdN!Bd58sktjad\n",
            "OpP?8ju5,ğ3Bmt!tfZÖıaİ.P:h6fE-cOGe\n",
            "Yö:T2GgşÖR-CUP:F!öÖA28ffItDPzİsd0kd2Hm\n",
            "ÇI!Fc\n",
            "SY0z0cKaİB,Y0Ik8öjşyÖ?Ö9ğggm!pÇeğ2Ü3cLmln0KBNğ:p\n",
            "IİiövfKKİNicndYİşHödm3KC87pY'81VşB95'!phrAB'.öY;Gıye\n",
            "ö0:cöRv5EÇnüMp34YeÖAçuSY0pİü'ö3G1çIb;öa\n",
            "ğ4Bc:bBBeYy5ğ3E'1çF0:jÇu1B5cA04u;PfdÖ7Ü'3-ğöÖua;ömpEZ8jBlhy5-I,ı NcuOgNYğ??\n",
            "çI-!cdö:LN3föcj!ı\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for iter in range(max_iters):\n",
        "  if iter % eval_interval == 0:\n",
        "    losses = estimation_loss()\n",
        "    print(f\"step: {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
        "  xb,yb=get_batch(\"train\")\n",
        "  logits,loss = m(xb,yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
        "print(decoder(m.generate(context,max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmuPqQQkA-Zs",
        "outputId": "1430883d-6c2f-4766-e688-89b89e622d59"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0: train loss: 4.5017, val loss: 4.5016\n",
            "step: 500: train loss: 1.7423, val loss: 1.8774\n",
            "step: 1000: train loss: 0.9659, val loss: 2.0056\n",
            "step: 1500: train loss: 0.2119, val loss: 3.1427\n",
            "step: 2000: train loss: 0.0937, val loss: 3.8597\n",
            "step: 2500: train loss: 0.0730, val loss: 4.2735\n",
            "step: 3000: train loss: 0.0637, val loss: 4.5403\n",
            "step: 3500: train loss: 0.0571, val loss: 4.7067\n",
            "step: 4000: train loss: 0.0545, val loss: 4.8597\n",
            "step: 4500: train loss: 0.0521, val loss: 4.9284\n",
            "\n",
            "\n",
            "Rubai 308:\n",
            "Her gün şarap cümbüşüne dalanların da\n",
            "Her gece mihrap önünde kalanların da\n",
            "Islanmaya yok, yok.\n",
            "Key ve de ba, çünkü yükse ver diler önünde.\n",
            "\n",
            "Rubai 132:\n",
            "Bu dünya gönül dedenin canımın kanlar\n",
            "Ne hamutlu kanlar halk varamış bir zaman\n",
            "Senda bu şerde görer gibi ocak önünden.\n",
            "\n",
            "Rubai 120:\n",
            "Tanrı' ı55:\n",
            "Yokların dolan mezaneyin;\n",
            "Ama Maklanları önümün derinin;\n",
            "Bunların mi virgi kader cim deli, sana gibi;\n",
            "Bu dünyadık yerde kalması yok, yağmur.\n",
            "\n",
            "Rubai 154:\n",
            "Kimi de imiş ki bir taprsın kana:\n",
            "Bir git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.save_pretrained(\"model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "kh8aNDw-ab_l",
        "outputId": "91888e87-eb04-4ec8-9c37-31731ff84156"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'BigramLanguageModel' object has no attribute 'save_pretrained'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-4193020585.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BigramLanguageModel' object has no attribute 'save_pretrained'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "akQF3Dshag8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}